{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths for the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_data_train = \"BSR_bsds500\\BSR\\BSDS500\\data\\images\\\\train\"\n",
    "path_data_test = \"BSR_bsds500\\BSR\\BSDS500\\data\\images\\\\test\"\n",
    "path_data_validate = \"BSR_bsds500\\BSR\\BSDS500\\data\\images\\\\val\"\n",
    "\n",
    "# path_data_train = \"BSR_bsds500/BSR_bsds500/BSR/BSDS500/data/images/train\"\n",
    "# path_data_test = \"BSR_bsds500/BSR_bsds500/BSR/BSDS500/data/images/test\"\n",
    "# path_data_validate =\"BSR_bsds500/BSR_bsds500/BSR/BSDS500/data/images/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting images to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "def preprocess_input(input_file_path):\n",
    "    input_file_list = os.listdir(input_file_path)\n",
    "    img_data_list = []\n",
    "    for file in input_file_list:\n",
    "        img = cv2.imread(input_file_path+'\\\\'+file)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_data_list.append(gray)\n",
    "    print (\"Converted \"+str(len(img_data_list))+ \" images to greyscale.\")\n",
    "    inp_data = np.array(img_data_list)\n",
    "    print(inp_data.shape)\n",
    "    return inp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing images in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train_list = preprocess_input(path_data_train)\n",
    "data_test_list = preprocess_input(path_data_test)\n",
    "data_validate_list = preprocess_input(path_data_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating patches adding noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract clean and noisy patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_patches(input_list, size):\n",
    "    print(\"Extracting patches...\")\n",
    "    print(len(input_list))\n",
    "    clean_patch_list = []\n",
    "    noisy_patch_list = []\n",
    "    for clean_image in itertools.islice(input_list, 0, len(input_list)):\n",
    "        for(x,y, window) in sliding_window(clean_image, stepSize=size, windowSize=(size,size)):\n",
    "            if window.shape[0] != size or window.shape[1] != size:\n",
    "                continue\n",
    "            clean_patch=window\n",
    "            if clean_patch.shape[0] != size or clean_patch.shape[1] != size:\n",
    "                continue\n",
    "            clean_patch_list.append(clean_patch)\n",
    "\n",
    "            noisy_patch = clean_patch.copy()\n",
    "            noisy_patch = np.add(noisy_patch, ( 25 * np.random.random(noisy_patch.shape)))\n",
    "            noisy_patch = np.clip(noisy_patch,0,255.0)\n",
    "            noisy_patch_list.append(noisy_patch)\n",
    "                \n",
    "    clean_patches = np.asarray([arr.flatten().astype(np.float32) for arr in clean_patch_list])\n",
    "    noisy_patches = np.asarray([arr.flatten().astype(np.float32) for arr in noisy_patch_list])\n",
    "    print(\"Total patches extracted: \" + str(clean_patches.shape))\n",
    "    print(\"Single patche size: \" + str(clean_patches[1].shape))\n",
    "\n",
    "    return (clean_patches, noisy_patches)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_patches = np.asarray(get_patches(data_train_list, 8))\n",
    "test_patches = np.asarray(get_patches(data_test_list, 8))\n",
    "val_patches = np.asarray(get_patches(data_validate_list, 8))\n",
    "\n",
    "train_patches_16 = np.asarray(get_patches(data_train_list, 16))\n",
    "test_patches_16 = np.asarray(get_patches(data_test_list, 16))\n",
    "val_patches_16 = np.asarray(get_patches(data_validate_list, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noramlize the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INPUT DATA 8x8 FOR THE MODEL IN PROPER SHAPE\n",
    "x_train_clean = train_patches[0] \n",
    "x_train_clean = x_train_clean/255.0\n",
    "x_train_clean = x_train_clean.reshape(((len(x_train_clean)),64))\n",
    "\n",
    "x_train_noisy = train_patches[1] \n",
    "x_train_noisy = x_train_noisy/255.0\n",
    "x_train_noisy = x_train_noisy.reshape(((len(x_train_noisy)),64))\n",
    "\n",
    "x_test_clean = test_patches[0] \n",
    "x_test_clean = x_test_clean/255.0\n",
    "x_test_clean = x_test_clean.reshape(((len(x_test_clean)),64))\n",
    "\n",
    "x_test_noisy = test_patches[1] \n",
    "x_test_noisy = x_test_noisy/255.0\n",
    "x_test_noisy = x_test_noisy.reshape(((len(x_test_noisy)),64))\n",
    "\n",
    "###################\n",
    "\n",
    "# INPUT DATA 16x16 FOR THE MODEL IN PROPER SHAPE\n",
    "x_train_clean_16 = train_patches_16[0] \n",
    "x_train_clean_16 = x_train_clean_16/255.0\n",
    "x_train_clean_16 = x_train_clean_16.reshape(((len(x_train_clean_16)),256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder consists of an input layer and a single encoding layer and a single decoding layer. The model is trained with clean images as input and clean images as output. The weights of the encoding layer are stored after training.\n",
    "    This function returns the encoder model that maps the input layer to its encoded representation, and the weights of the encoder layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0,\n",
    "                                         write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_autoencoder(i_dim, e_dim, train, name):\n",
    "    #input dimension\n",
    "    input_dim = i_dim*i_dim\n",
    "    #encoding dimension\n",
    "    encoding_dim = e_dim*e_dim\n",
    "    \n",
    "    #AUTOENCODER_MODEL\n",
    "\n",
    "    #input layer\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    #encoded layer \n",
    "    e_name = str(name)+'_en_d'\n",
    "    encoding_layer = Dense(encoding_dim, activation='relu', kernel_initializer='random_normal', name=e_name)(input_layer)\n",
    "    \n",
    "    #decoding layer\n",
    "    d_name = str(name)+'_de_d'\n",
    "    decoding_layer = Dense(input_dim, activation='sigmoid', kernel_initializer='random_normal', name=d_name)(encoding_layer)\n",
    "    \n",
    "    #model\n",
    "    auto_1 = Model(input_layer, decoding_layer)\n",
    "    \n",
    "    #compile\n",
    "    auto_1.compile(optimizer='adadelta', loss ='mean_squared_error', metrics=['accuracy'])\n",
    "    \n",
    "    #train\n",
    "    auto_1.fit(train, train,\n",
    "          epochs = 40,\n",
    "          verbose =1,\n",
    "          batch_size = 100,\n",
    "          shuffle = True,\n",
    "          validation_split=0.33,\n",
    "          callbacks=[tbCallBack])\n",
    "\n",
    "    #save all weights\n",
    "    w_name = 'encoded'+str(name)+'weights.h5'\n",
    "    auto_1.save_weights(w_name) # save weights\n",
    "    \n",
    "    #save weights of encoder layer\n",
    "    weights = auto_1.layers[1].get_weights()\n",
    "       \n",
    "    #ENCODER MODEL : mapping input to the encoded representation\n",
    "    encoder = Model(input_layer, encoding_layer)\n",
    "    #load weights of encoding layer from the trained model (weights of layers with same name loaded)\n",
    "    encoder.load_weights(w_name, by_name=True) \n",
    "    #compile\n",
    "    encoder.compile(optimizer='adadelta', loss = 'mean_squared_error')\n",
    "\n",
    "    #return the ecnoder model for feed forwarding and the weights of the encoder layer to use in SSDA\n",
    "    return (encoder, weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOENCODER MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FIT MODEL 1\n",
    "autoencoder1 = my_autoencoder(8, 16, x_train_clean, 1)\n",
    "# save weights of encoder layer from model 1\n",
    "wt1 = autoencoder1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](loss_1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>loss vs epoch (autoencoder 1)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEED FORWARDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder model obtained from the previous step is fed with the clean and noisy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FEED FORWARDING 1\n",
    "encoded_imgs_clean = autoencoder1[0].predict(x_train_clean)\n",
    "encoded_imgs_noisy = autoencoder1[0].predict(x_train_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOENCODER MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FIT MODEL\n",
    "autoencoder2 = my_autoencoder(16, 32, x_train_clean_16, 2)\n",
    "# save weights of encoder layer from model 2\n",
    "wt2 = autoencoder2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](loss_2.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>loss vs epoch (autoencoder 2)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEED FORWARDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder model obtained from the second autoencoder is fed with the clean and noisy output of the first autoencoder's feed forward step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PREDICTIONS / TESTS\n",
    "encoded_imgs_clean2 = autoencoder2[0].predict(encoded_imgs_clean)\n",
    "encoded_imgs_noisy2 = autoencoder2[0].predict(encoded_imgs_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SSDA has a input layer, 2 encoding layers that take the input from 8x8 to 16x16 and 16x16 to 32x32. The weights of these layers are initialised using the weights of the first two autoencoders stored earlier. Then comes two decoding layers that bring the 32X32 image to 16x16 and then to 8x8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ssda(w1, w2, noisy, clean):\n",
    "  \n",
    "    #AUTOENCODER_MODEL\n",
    "\n",
    "    #input layer\n",
    "    input_layer = Input(shape=(8*8,))\n",
    " \n",
    "    #encoded layer \n",
    "    encoding_layer_8_16 = Dense(16*16, activation='relu', name='ssd_e_16')(input_layer)\n",
    "    encoding_layer_16_32 = Dense(32*32, activation='relu', name='ssd_e_32')(encoding_layer_8_16)\n",
    "\n",
    "    #decoding layer\n",
    "    decoding_layer_32_16 = Dense(16*16, activation='sigmoid', name='ssd_d_32')(encoding_layer_16_32)\n",
    "    decoding_layer_16_8 = Dense(8*8, activation='sigmoid', name='ssd_d_16')(decoding_layer_32_16)\n",
    "    \n",
    "    #MODEL\n",
    "    ssda_model = Model(inputs=[input_layer], outputs=[decoding_layer_16_8])\n",
    "    \n",
    "    ssda_model.layers[1].set_weights(w1)\n",
    "    ssda_model.layers[2].set_weights(w2)\n",
    "    \n",
    "    ssda_model.compile(optimizer='adadelta', loss = 'mean_squared_error')\n",
    "    \n",
    "    ssda_model.fit(noisy, clean,\n",
    "          epochs = 30,\n",
    "          verbose =2,\n",
    "          batch_size = 1000,\n",
    "          shuffle = True,\n",
    "          validation_split=0.33,\n",
    "          callbacks=[tbCallBack])  \n",
    "    \n",
    "    ssda_model.save_weights('ssda_wts')\n",
    "    \n",
    "    return ssda_model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ssda(wt1, wt2, x_train_noisy, x_train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](loss_ssda.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>loss vs epoch (SSDA)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TEST USING NOISY INPUT\n",
    "img = model.predict(x_test_noisy)\n",
    "\n",
    "# saving the output to a file for future use\n",
    "import pickle\n",
    "with open('outfile', 'wb') as fp:\n",
    "    pickle.dump(img, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a few random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure as sk\n",
    "\n",
    "n = 10 \n",
    "k = 50\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    ax.set_title('Patch : ' + str(i*k))\n",
    "    plt.imshow(x_test_clean[i*k].reshape(8,8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "for i in range(n):\n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i + 1 +n)\n",
    "    ax.set_title('PSNR: ' + str(round(sk.compare_psnr(x_test_clean[i*k],x_test_noisy[i*k]),2)))\n",
    "    plt.imshow(x_test_noisy[i*k].reshape(8,8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "for i in range(n):\n",
    "    # display deniosed\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    ax.set_title('PSNR: ' + str(round(sk.compare_psnr(x_test_clean[i*k],itemlist[i*k]),2)))\n",
    "    plt.imshow(itemlist[i*k].reshape(8,8))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Capture3.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Top: Clean image, Middle: Noisy Input, Bottom: Denoised Image</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Clean test image\n",
    "plt.imshow(data_validate_list[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Noisy test image\n",
    "plt.imshow(np.add(data_validate_list[10], 25*np.random.random(data_validate_list[10].shape)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convering test images to patches\n",
    "test_image = np.asarray(get_patches(data_test_list[10:11], 8))\n",
    "test_image_clean = test_image[0]\n",
    "test_image_clean = test_image_clean/255.0\n",
    "test_image_clean = test_image_clean.reshape(((len(test_image_clean)),64))\n",
    "\n",
    "test_image_noisy = test_image[1]\n",
    "test_image_noisy = test_image_noisy/255.0\n",
    "test_image_noisy = test_image_noisy.reshape(((len(test_image_noisy)),64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_res = model.predict(test_image_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('test_op', 'wb') as fp:\n",
    "    pickle.dump(test_res, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # from file\n",
    "plt.subplot(131)\n",
    "plt.imshow(data_test_list[10][0:8,8:16].reshape(8,8))\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "# # from patch noisy\n",
    "plt.subplot(132)\n",
    "plt.imshow(test_image_noisy[1].reshape(8,8)*255)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "# # from patch denoised\n",
    "plt.subplot(133)\n",
    "plt.imshow(test_res[1].reshape(8,8)*255)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](test.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<center>Patch no.2 from the test image</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
